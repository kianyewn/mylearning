{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3deee93a",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/cdeotte/tensorflow-roberta-0-705/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a3705ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c739f9",
   "metadata": {},
   "source": [
    "Roberta details\n",
    "<pre>\n",
    "  \"architectures\": [\n",
    "    \"RobertaForMaskedLM\"\n",
    "  ],\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"bos_token_id\": 0,\n",
    "  \"eos_token_id\": 2,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 768,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"layer_norm_eps\": 1e-05,\n",
    "  \"max_position_embeddings\": 514,\n",
    "  \"model_type\": \"roberta\",\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 12,\n",
    "  \"pad_token_id\": 1,\n",
    "  \"type_vocab_size\": 1,\n",
    "  \"vocab_size\": 50265\n",
    " </pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887ed48",
   "metadata": {},
   "source": [
    " Example vocab:\n",
    " <pre>\n",
    " {\"<s>\": 0, \"<pad>\": 1, \"</s>\": 2, \"<unk>\": 3, \".\": 4, \"ƒ†the\": 5, \",\": 6, \"ƒ†to\": 7, \"ƒ†and\": 8, \"ƒ†of\": 9, \"ƒ†a\": 10, \"ƒ†in\": 11, \"-\": 12, \"ƒ†for\": 13, \"ƒ†that\": 14, \"ƒ†on\": 15, \"ƒ†is\": 16, \"√¢ƒ¢\": 17, \"'s\": 18, \"ƒ†with\": 19, \"ƒ†The\": 20, \"ƒ†was\": 21, \"ƒ†\\\"\": 22, \"ƒ†at\": 23, \"ƒ†it\": 24, \"ƒ†as\": 25, \"ƒ†said\": 26, \"ƒª\": 27, \"ƒ†be\": 28, \"s\": 29, \"ƒ†by\": 30, \"ƒ†from\": 31, \"ƒ†are\": 32, \"ƒ†have\": 33, \"ƒ†has\": 34, \":\": 35, \"ƒ†(\": 36, \"ƒ†he\": 37, \"ƒ†I\": 38, \"ƒ†his\": 39, \"ƒ†will\": 40, \"ƒ†an\": 41, \"ƒ†this\": 42, \")\": 43, \"ƒ†√¢ƒ¢\": 44, \"ƒ†not\": 45, \"ƒø\": 46, \"ƒ†you\": 47, \"ƒæ\": 48, \"ƒ†their\": 49, \"ƒ†or\": 50, \"ƒ†they\": 51, \"ƒ†we\": 52, \"ƒ†but\": 53, \"ƒ†who\": 54, \"ƒ†more\": 55, \"ƒ†had\": 56\n",
    " </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roberta special tokens\n",
    "# - ['<s>', '</s>', '<unk>', '<pad>', '<mask>']\n",
    "\n",
    "special token ids\n",
    "[0, 2, 3, 1, 50264]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26069e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 'x', 2, 2, 'y', 2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.build_inputs_with_special_tokens(['x'], ['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2328e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '<unk>', '<pad>', '<mask>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d52ad79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 1, 50264]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e88a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (‚Ä¶)olve/main/vocab.json: 100%|‚ñà| 899k/899k [00:0\n",
      "Downloading (‚Ä¶)olve/main/merges.txt: 100%|‚ñà| 456k/456k [00:0\n",
      "Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà| 481/481 [00:00<\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d0e88bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 22173, 2], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27e8ec",
   "metadata": {},
   "source": [
    "For some reason, roberta tokenizer from pretrained is different from directly calling ByteLevelBPETokenizer\n",
    "eg, ID for 'positive' is 22173 in autotokenizer, but 1313 in ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "797d7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "# does not work\n",
    "# tokenizers.ByteLevelBPETokenizer.from_pretrained('roberta-base')\n",
    "ROBERTA_PATH = \"/Users/kianyewngieng/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68\"\n",
    "TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab=f\"{ROBERTA_PATH}/vocab.json\", \n",
    "    merges=f\"{ROBERTA_PATH}/merges.txt\", \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "tokenizer = TOKENIZER\n",
    "\n",
    "sentiment_id = {'positive': 1313, 'negative':2430, 'neutral': 7974}\n",
    "\n",
    "train = pd.read_csv('../data/tweet-sentiment-extraction/train.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e9f9165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape # 24k sample size for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c1d77013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63f450",
   "metadata": {},
   "source": [
    "##  Tokenize train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb755052",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 96\n",
    "\n",
    "ct = train.shape[0]\n",
    "input_ids = np.ones((ct, MAX_LEN), dtype='int32')\n",
    "attention_mask = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "token_type_ids = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "start_tokens = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "end_tokens = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "\n",
    "for k in range(train.shape[0]):\n",
    "    # adds a space in front\n",
    "    text1  = \" \" + \" \".join(train.loc[k, 'text'].split())\n",
    "    text2 = \" \".join(train.loc[k, 'selected_text'].split())\n",
    "    # return start index for the substring\n",
    "    idx = text1.find(text2)\n",
    "    chars = np.zeros((len(text1)))\n",
    "    \n",
    "    # token_ids for the sample\n",
    "    chars[idx:idx+len(text2)] = 1\n",
    "    # fill up the \n",
    "    if text1[idx-1]==' ':\n",
    "        chars[idx-1] = 1\n",
    "    \n",
    "    enc = tokenizer.encode(text1)\n",
    "    \n",
    "    # id_offsets\n",
    "    # For each sub-token returned by the tokenizer, \n",
    "    # the offset mapping gives us a tuple indicating the \n",
    "    # sub-token‚Äôs start position and end position relative to\n",
    "    # the original token it was split from. \n",
    "    # That means that if the first position in the tuple is \n",
    "    # anything other than 0, we will set its corresponding label to -100. \n",
    "    # While we‚Äôre at it, we can also set labels to -100 \n",
    "    # if the second position of the offset mapping is 0, \n",
    "    # since this means it must be a special token like [PAD] or [CLS].\n",
    "    offsets = []\n",
    "    idx = 0\n",
    "    for t in enc.ids:\n",
    "        w = tokenizer.decode([t])\n",
    "        offsets.append([idx, idx+len(w)])\n",
    "        idx += len(w)\n",
    "        \n",
    "    # START END TOKENS\n",
    "    toks = []\n",
    "    for i, (a,b) in enumerate(offsets):\n",
    "        sm = np.sum(chars[a:b])\n",
    "        if sm>0: \n",
    "            toks.append(i)\n",
    "            \n",
    "    s_tok = sentiment_id[train.loc[k, 'sentiment']]\n",
    "    input_ids[k, :len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask[k, :len(enc.ids)+5] = 1\n",
    "    if len(toks)>0:\n",
    "        start_tokens[k, toks[0]+1] = 1\n",
    "        end_tokens[k, toks[-1] + 1] = 1\n",
    "    \n",
    "#     if k == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fb4e4ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3), (3, 8), (8, 11), (11, 20), (20, 23), (23, 26)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6a2c0ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' my boss is bullying me...'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bdd29489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[127, 3504, 16, 11902, 162, 734]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ad51e6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' my boss is bullying me...'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e3f61cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bullying me'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21baaf11",
   "metadata": {},
   "source": [
    "##### tokenizer does not split on beginning of sentence \" \"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "95666fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[127, 3504, 16, 11902, 162, 734]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text1).ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5ea611bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my boss is bullying me...'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1_v2 = text1[1:]\n",
    "text1_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ee68808d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[127, 3504, 16, 11902, 162, 734]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text1_v2).ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4a023680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' my'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([127])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196d4a7",
   "metadata": {},
   "source": [
    "/end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a7039f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,   127,  3504,    16, 11902,   162,   734,     2,     2,\n",
       "        2430,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1], dtype=int32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9efcae5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "03d8e492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3], [3, 8], [8, 11], [11, 20], [20, 23], [23, 26]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d393b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "893935b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_tokens[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b7ecf760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_tokens[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "   s_tok = sentiment_id[train.loc[k,'sentiment']]\n",
    "    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask[k,:len(enc.ids)+5] = 1\n",
    "    if len(toks)>0:\n",
    "        start_tokens[k,toks[0]+1] = 1\n",
    "        end_tokens[k,toks[-1]+1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4745e92e",
   "metadata": {},
   "source": [
    "Now we arrive at a common obstacle with using pre-trained models for token-level classification: many of the tokens in the W-NUT corpus are not in DistilBert‚Äôs vocabulary. Bert and many models like it use a method called WordPiece Tokenization, meaning that single words are split into multiple tokens such that each token is likely to be in the vocabulary. For example, DistilBert‚Äôs tokenizer would split the Twitter handle @huggingface into the tokens ['@', 'hugging', '##face']. This is a problem for us because we have exactly one tag per token. If the tokenizer splits a token into multiple sub-tokens, then we will end up with a mismatch between our tokens and our labels.\n",
    "\n",
    "One way to handle this is to only train on the tag labels for the first subtoken of a split token. We can do this in ü§ó Transformers by setting the labels we wish to ignore to -100. In the example above, if the label for @HuggingFace is 3 (indexing B-corporation), we would set the labels of ['@', 'hugging', '##face'] to [3, -100, -100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c6228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2029392",
   "metadata": {},
   "source": [
    "### tokenize test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b462a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/tweet-sentiment-extraction/test.csv').fillna('')\n",
    "ct = test.shape[0]\n",
    "input_ids = np.ones((ct, MAX_LEN), dtype='int32')\n",
    "attention_mask_t = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "token_type_ids_t = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "\n",
    "for k in range(test.shape[0]):\n",
    "    text1 = \" \" + \" \".join(test.loc[k, 'text'].split())\n",
    "    enc = tokenizer.encode(text1)\n",
    "    s_tok = sentiment_id[test.loc[k,'sentiment']]\n",
    "    input_ids[k, :len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask_t[k, len(enc.ids)+5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372b23bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3534, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c9ad4b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "bert_model = AutoModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f747280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "input_ids = torch.from_numpy(input_ids) # , dtype=torch.int64)\n",
    "attention_mask = torch.from_numpy(attention_mask_t) # , dtype=torch.int64)\n",
    "token_type_ids = torch.from_numpy(token_type_ids_t) # , dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54a8bfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3534, 96])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b507a03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3534, 96])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cac3857b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3534, 96])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b694c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce600475",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "61ad2fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fef6554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bert_model(input_ids=input_ids[[2]], \n",
    "           attention_mask=attention_mask[[2]],\n",
    "           token_type_ids=token_type_ids[[2]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6edd9aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0518,  0.0734, -0.0339,  ..., -0.1223, -0.0407, -0.0231],\n",
       "         [-0.0561,  0.0678, -0.0304,  ..., -0.1155, -0.0411, -0.0226],\n",
       "         [-0.0516,  0.0701, -0.0300,  ..., -0.1202, -0.0383, -0.0211],\n",
       "         ...,\n",
       "         [-0.0671,  0.0620, -0.0265,  ..., -0.1117, -0.0480, -0.0200],\n",
       "         [-0.0671,  0.0620, -0.0265,  ..., -0.1117, -0.0480, -0.0200],\n",
       "         [-0.0671,  0.0620, -0.0265,  ..., -0.1117, -0.0480, -0.0200]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0123, -0.2211, -0.2488, -0.0714,  0.1332,  0.1888,  0.2768, -0.1189,\n",
       "         -0.0821, -0.1937,  0.2648,  0.0115, -0.1351,  0.0860, -0.1485,  0.4940,\n",
       "          0.2344, -0.4982,  0.0320, -0.0089, -0.2283,  0.0748,  0.4725,  0.3132,\n",
       "          0.1108,  0.0729, -0.1433, -0.0355,  0.1917,  0.2477,  0.2759,  0.0387,\n",
       "          0.1500,  0.2116, -0.2434,  0.0748, -0.3380, -0.0159,  0.2932, -0.1931,\n",
       "         -0.0731,  0.1764,  0.2287, -0.1756, -0.1225,  0.4253,  0.2291,  0.0461,\n",
       "         -0.1226, -0.0680, -0.3591,  0.3606,  0.3015,  0.1936, -0.0681,  0.0261,\n",
       "         -0.1251,  0.2660, -0.0809, -0.0868, -0.1245, -0.2239, -0.0244, -0.0313,\n",
       "          0.0291, -0.1347,  0.0924, -0.1853, -0.1391,  0.0338, -0.1186,  0.1235,\n",
       "          0.1636, -0.2875, -0.2688,  0.0582, -0.6159, -0.1221,  0.3070,  0.4265,\n",
       "         -0.1136,  0.2278,  0.0246,  0.2445,  0.0007, -0.0626, -0.0184, -0.1076,\n",
       "          0.1857,  0.2726, -0.2103, -0.4478,  0.0464,  0.0108, -0.1277, -0.0089,\n",
       "          0.0033, -0.0987, -0.1552, -0.1729,  0.0786, -0.2734, -0.1339,  0.2644,\n",
       "         -0.0122, -0.2451, -0.0413,  0.3109,  0.0427, -0.1418, -0.1803,  0.4224,\n",
       "          0.3370,  0.0324, -0.0031,  0.1848,  0.0846, -0.2919,  0.4293, -0.3464,\n",
       "         -0.0007, -0.0981,  0.1490,  0.1370, -0.2160,  0.2666,  0.1411,  0.2766,\n",
       "          0.1725,  0.0802, -0.0331,  0.1242, -0.1366,  0.1387,  0.1902,  0.0852,\n",
       "         -0.0176, -0.3202, -0.2702,  0.2725,  0.3578,  0.1290, -0.0159,  0.2337,\n",
       "          0.1073,  0.2086,  0.1570, -0.4195,  0.0714,  0.3735,  0.1065,  0.1668,\n",
       "         -0.1030, -0.2955, -0.2753, -0.0963,  0.0375, -0.3624, -0.1080,  0.3748,\n",
       "         -0.0106, -0.0270, -0.1550, -0.2035, -0.0337, -0.1310,  0.0125,  0.0977,\n",
       "         -0.0666, -0.4218, -0.0987, -0.5267, -0.1254,  0.2443, -0.2959,  0.2589,\n",
       "         -0.3306,  0.1106,  0.4184,  0.0088, -0.0032, -0.2124,  0.0136,  0.0782,\n",
       "          0.3204,  0.2433, -0.3969,  0.0877,  0.1317,  0.2521,  0.1383, -0.0156,\n",
       "         -0.1406,  0.1678, -0.2274,  0.1871, -0.2498,  0.1928, -0.2434, -0.2249,\n",
       "          0.2930, -0.4090, -0.0813,  0.0977,  0.2843,  0.0321, -0.0811, -0.1181,\n",
       "          0.1047,  0.1944,  0.1390, -0.4024,  0.2827,  0.0062, -0.0168, -0.0434,\n",
       "          0.1476,  0.2063,  0.1479, -0.3847, -0.1149,  0.1406,  0.2581, -0.2796,\n",
       "          0.1615, -0.2909, -0.4047, -0.1138,  0.2240,  0.2828,  0.1631, -0.2598,\n",
       "          0.1473, -0.1264, -0.4344, -0.3872, -0.1250,  0.2810,  0.1891,  0.1634,\n",
       "          0.2514,  0.0770,  0.1290,  0.1402,  0.1502, -0.1716,  0.1613, -0.3850,\n",
       "         -0.0879, -0.2885, -0.1816, -0.2384,  0.4364, -0.2454,  0.2339,  0.4111,\n",
       "         -0.2963, -0.1205,  0.1274,  0.1071,  0.1022, -0.1209,  0.2213,  0.1707,\n",
       "         -0.1190,  0.2573,  0.0324,  0.2638,  0.1421,  0.0998,  0.1383,  0.1368,\n",
       "         -0.1536,  0.0801,  0.0240, -0.0344, -0.2543, -0.1600,  0.2540, -0.0423,\n",
       "          0.0492, -0.1596, -0.0876, -0.0140,  0.4245, -0.3842,  0.2498,  0.0843,\n",
       "          0.1281, -0.2650, -0.1868,  0.0841,  0.2091, -0.4231,  0.0604,  0.1548,\n",
       "          0.0875,  0.1762,  0.2654, -0.0261, -0.1700,  0.4879, -0.1671, -0.1490,\n",
       "          0.2640, -0.2773, -0.2826,  0.2633, -0.0109,  0.3118,  0.0818,  0.0236,\n",
       "          0.1132, -0.6287,  0.0601, -0.4581, -0.0142,  0.0096, -0.0999, -0.2373,\n",
       "          0.1255,  0.2874, -0.2667, -0.0611,  0.2151,  0.0509, -0.0867,  0.4866,\n",
       "         -0.0191,  0.2049, -0.0812,  0.2736, -0.2376,  0.2616, -0.2633, -0.1022,\n",
       "          0.0413,  0.0928,  0.0744, -0.0527, -0.3820,  0.2585, -0.0519, -0.0476,\n",
       "         -0.0520,  0.1333, -0.0160,  0.0134,  0.0652,  0.3586,  0.2593, -0.0379,\n",
       "         -0.3834,  0.0054, -0.1089,  0.0779,  0.0219,  0.0155,  0.4498, -0.1010,\n",
       "         -0.0008, -0.1395,  0.2790,  0.2029,  0.1419,  0.1574,  0.0446,  0.1669,\n",
       "         -0.0631, -0.0095, -0.1613, -0.2443, -0.3073,  0.2241, -0.2744, -0.1847,\n",
       "          0.1657,  0.1711, -0.1124,  0.1274,  0.3311,  0.0954, -0.1504,  0.2298,\n",
       "         -0.1148,  0.0961,  0.3064, -0.0319,  0.1915,  0.5452,  0.2289, -0.3804,\n",
       "         -0.0516, -0.2337, -0.0130,  0.2713, -0.1502,  0.1728,  0.4125,  0.2949,\n",
       "          0.4777, -0.0020, -0.1265,  0.1145,  0.2383,  0.0243, -0.1914, -0.1697,\n",
       "          0.2784,  0.0463, -0.1038,  0.0175, -0.1328,  0.0502, -0.1337, -0.4143,\n",
       "          0.0609,  0.2092, -0.4829,  0.1412, -0.3402,  0.0138, -0.2112,  0.2318,\n",
       "         -0.2924, -0.1388,  0.3893, -0.0891,  0.0456, -0.2107, -0.1778,  0.0420,\n",
       "          0.0155,  0.0050, -0.0302,  0.3415, -0.1332,  0.0264,  0.0267,  0.2108,\n",
       "         -0.0685,  0.2043,  0.0397, -0.1349, -0.4266,  0.1898, -0.2123, -0.4077,\n",
       "         -0.3653,  0.3804, -0.1344, -0.2491, -0.2218, -0.2585,  0.0482,  0.1580,\n",
       "          0.4296, -0.3762, -0.0611,  0.5144, -0.0295, -0.1976,  0.2666,  0.2200,\n",
       "         -0.3347,  0.3940,  0.2973, -0.0564,  0.0060,  0.5350,  0.1273,  0.2151,\n",
       "         -0.2190,  0.4611, -0.2472,  0.3230, -0.1787, -0.2292, -0.2483, -0.0252,\n",
       "          0.3359,  0.1843, -0.4414, -0.1097,  0.0461,  0.3414, -0.3617, -0.0901,\n",
       "          0.0200, -0.3417,  0.0803,  0.1014,  0.2095, -0.4185, -0.0560,  0.3954,\n",
       "         -0.3497,  0.1017,  0.3212,  0.0757,  0.3683, -0.0200, -0.0374,  0.0768,\n",
       "         -0.2699, -0.0426,  0.1399,  0.5695,  0.1249, -0.4081,  0.1045,  0.2615,\n",
       "         -0.1397,  0.3310, -0.1062, -0.0796,  0.3004, -0.0607,  0.1509, -0.0778,\n",
       "         -0.2638, -0.3361,  0.3723, -0.2383, -0.0886, -0.1908, -0.0851, -0.1461,\n",
       "          0.0339, -0.4041,  0.3699,  0.1584, -0.2190, -0.0798, -0.0973, -0.1521,\n",
       "         -0.2230, -0.2847,  0.4314, -0.1698, -0.4677,  0.2720,  0.0503,  0.3558,\n",
       "          0.0152,  0.1344, -0.0559,  0.1434,  0.0989, -0.1175,  0.2725,  0.1042,\n",
       "         -0.5814, -0.1195, -0.2533,  0.0660,  0.2292, -0.3507,  0.0248,  0.0262,\n",
       "          0.1356,  0.0533, -0.1111, -0.0840,  0.3809,  0.2502,  0.2593,  0.1451,\n",
       "          0.1964, -0.0123, -0.3292,  0.0433,  0.0654, -0.1813,  0.4353, -0.1057,\n",
       "         -0.4109, -0.0843,  0.4212,  0.1260, -0.0670, -0.0483,  0.2070,  0.1252,\n",
       "         -0.0790,  0.1463, -0.0595, -0.1538, -0.1353,  0.0992, -0.2283,  0.0622,\n",
       "         -0.1935, -0.0074, -0.2159,  0.0039, -0.2147,  0.2779, -0.3649,  0.1137,\n",
       "          0.0511,  0.3079, -0.3670, -0.1680, -0.0439,  0.1968,  0.2426,  0.3692,\n",
       "          0.0359,  0.0690, -0.1754, -0.2597,  0.0510, -0.2112,  0.1192,  0.0780,\n",
       "          0.2469, -0.3326, -0.1827,  0.1765, -0.0543, -0.1858,  0.4512,  0.2421,\n",
       "          0.2432,  0.0162,  0.2720,  0.0113, -0.2364, -0.1371, -0.2827,  0.0818,\n",
       "         -0.0985, -0.0734, -0.0468, -0.0981, -0.1973, -0.1372,  0.1311,  0.1060,\n",
       "         -0.0018, -0.0737, -0.0090, -0.3121,  0.3340,  0.0296,  0.0570, -0.0233,\n",
       "          0.0554, -0.1893,  0.2369,  0.2406,  0.0792, -0.1807, -0.0392, -0.3295,\n",
       "         -0.3712,  0.0547,  0.1358,  0.1185, -0.1059, -0.2729,  0.0182, -0.0917,\n",
       "          0.1945,  0.0315, -0.1698, -0.1007, -0.0653, -0.0703,  0.0975, -0.1866,\n",
       "         -0.1975, -0.0914, -0.0575, -0.0761,  0.3706, -0.0611,  0.3221, -0.1810,\n",
       "         -0.0058, -0.1492,  0.1580, -0.0768,  0.0516,  0.2546, -0.4335, -0.1423,\n",
       "         -0.0224, -0.2343, -0.1289, -0.0472, -0.0288,  0.2363, -0.3360,  0.2141,\n",
       "         -0.1182,  0.1866, -0.0252, -0.2552, -0.1286,  0.0141,  0.2666, -0.3325,\n",
       "         -0.2463, -0.3173, -0.1323, -0.0855, -0.2820,  0.4570, -0.1388, -0.1039,\n",
       "          0.0456,  0.4450,  0.2067,  0.1497,  0.2278, -0.0560,  0.0133,  0.1498,\n",
       "         -0.4891,  0.2088, -0.2832, -0.1524,  0.0295,  0.1311, -0.0359,  0.0282,\n",
       "         -0.1601, -0.0472,  0.2138, -0.4119, -0.0433,  0.2638,  0.1166, -0.2440,\n",
       "          0.0295,  0.1334,  0.4004,  0.1538, -0.2137,  0.1328, -0.3361, -0.0126,\n",
       "         -0.1901, -0.3184,  0.1796, -0.0845,  0.0740, -0.0960, -0.3148,  0.2281,\n",
       "         -0.0375, -0.0561,  0.4384,  0.0057, -0.0627,  0.1206,  0.0217,  0.0575,\n",
       "         -0.0932,  0.2407,  0.1936, -0.2923,  0.1618, -0.1109, -0.0719, -0.1055]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aba9988b",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0064f94e",
   "metadata": {},
   "source": [
    "### Comparing Conv1d in pytorch and tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c0caa1c4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_1580/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">71761320.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_1580/71761320.py'</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 ‚îÇ   ‚îÇ   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 ‚îÇ   ‚îÇ   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 ‚îÇ   ‚îÇ   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">conv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">313</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 311 ‚îÇ   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 312 ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span> 313 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._conv_forward(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 314 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 315 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 316 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">Conv2d</span>(_ConvNd):                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">conv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">309</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_conv_forward</span>         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 306 ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.conv1d(F.pad(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reversed_padding_repeated_twice, mode=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">sel</span>  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 307 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>weight, bias, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.stride,                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 308 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>_single(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span> 309 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.conv1d(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, weight, bias, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.stride,                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 311 ‚îÇ   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 312 ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Given <span style=\"color: #808000; text-decoration-color: #808000\">groups</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, weight of size <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>, expected input<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">]</span> to have <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> channels, but got \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span> channels instead\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_1580/\u001b[0m\u001b[1;33m71761320.py\u001b[0m:\u001b[94m10\u001b[0m in \u001b[92m<module>\u001b[0m       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[3;31m'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_1580/71761320.py'\u001b[0m                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1501 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mconv.py\u001b[0m:\u001b[94m313\u001b[0m in \u001b[92mforward\u001b[0m               \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 310 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m.padding, \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 311 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 312 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m 313 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._conv_forward(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 314 \u001b[0m                                                                                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 315 \u001b[0m                                                                                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 316 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mConv2d\u001b[0m(_ConvNd):                                                                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mconv.py\u001b[0m:\u001b[94m309\u001b[0m in \u001b[92m_conv_forward\u001b[0m         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 306 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m F.conv1d(F.pad(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m._reversed_padding_repeated_twice, mode=\u001b[96msel\u001b[0m  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 307 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mweight, bias, \u001b[96mself\u001b[0m.stride,                                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 308 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m_single(\u001b[94m0\u001b[0m), \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m 309 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m F.conv1d(\u001b[96minput\u001b[0m, weight, bias, \u001b[96mself\u001b[0m.stride,                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 310 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m.padding, \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 311 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 312 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mGiven \u001b[33mgroups\u001b[0m=\u001b[1;36m1\u001b[0m, weight of size \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m, expected input\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m96\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m to have \u001b[1;36m768\u001b[0m channels, but got \n",
       "\u001b[1;36m96\u001b[0m channels instead\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lhs = x.last_hidden_state\n",
    "import torch.nn as nn\n",
    "\n",
    "# weihghts does not match the timestep dimension\n",
    "x1 = nn.Dropout(0.2)(lhs)\n",
    "convx1 = nn.Conv1d(in_channels = 768, \n",
    "               out_channels=1,\n",
    "               kernel_size=1,\n",
    "               stride=1)\n",
    "x1 = convx1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "931df890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 1])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convx1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5a667ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 768])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0b1aafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(4, 10, 128)\n",
    "tf_conv = tf.keras.layers.Conv1D(1,1)\n",
    "tf_out = tf_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "79613dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4542f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_conv = nn.Conv1d(128, 1, 1)\n",
    "nn_conv.weight = nn.Parameter(torch.tensor(tf_conv.get_weights()[0], dtype=torch.float))\n",
    "nn_out = nn_conv(torch.tensor(x, dtype=torch.float).transpose(-2,-1)).transpose(-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ae8156a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a35c65f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10, 1)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f90b642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_out = nn_out.detach().numpy()\n",
    "tf_out = tf_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "36284ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.1552157 ],\n",
       "       [-2.577402  ],\n",
       "       [-0.85579425],\n",
       "       [-1.0808017 ],\n",
       "       [-0.09038931],\n",
       "       [ 1.447653  ],\n",
       "       [ 0.4062286 ],\n",
       "       [ 0.38171047],\n",
       "       [-0.02897149],\n",
       "       [-0.73734987]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a654fbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.2065475 ],\n",
       "       [-2.5260706 ],\n",
       "       [-0.8044631 ],\n",
       "       [-1.0294701 ],\n",
       "       [-0.0390582 ],\n",
       "       [ 1.4989845 ],\n",
       "       [ 0.45756042],\n",
       "       [ 0.43304208],\n",
       "       [ 0.02236023],\n",
       "       [-0.6860184 ]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fea8cabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0fbf6413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10, 1])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4b03fb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10, 1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "input_shape = (4, 10, 128)\n",
    "x = tf.random.normal(input_shape)\n",
    "conv = tf.keras.layers.Conv1D(1,1)\n",
    "out = conv(x)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d09d5df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51cb8cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10, 128])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62b0ae2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e991082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10, 128])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5e8eee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c80947a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.3941005], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bcc7a326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.get_weights()[0].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c443641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a3077a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39410055"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(conv.get_weights()[0].squeeze() * x[0,0, :]).numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8646645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.271212"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,:].numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20aa2fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09586884"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,:].numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9c03c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08947609"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:, 0].numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a305fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0,:, 0].numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a76f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7878d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b548c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ef977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c96eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2821e029",
   "metadata": {},
   "source": [
    "### Build roberta model (Tensorflow) HAS BUG regarding tensorflow latest versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "70899e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3776479232.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/3776479232.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'keras.engine'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/\u001b[0m\u001b[1;33m3776479232.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[3;31m'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/3776479232.py'\u001b[0m                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'keras.engine'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.engine import data_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "59fd0714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1791973581.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/1791973581.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'keras.engine'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/\u001b[0m\u001b[1;33m1791973581.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[3;31m'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/1791973581.py'\u001b[0m                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'keras.engine'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow.python.keras as keras\n",
    "from keras.engine import data_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bcc5cb47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1172</span> in            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_module</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1169 ‚îÇ   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1170 ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_module</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module_name: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1171 ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1172 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> importlib.import_module(<span style=\"color: #808000; text-decoration-color: #808000\">\".\"</span> + module_name, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1173 ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1174 ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1175 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Failed to import {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}.{</span>module_name<span style=\"color: #808000; text-decoration-color: #808000\">} because of the followin</span>  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/importlib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">126</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">import_module</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> character != <span style=\"color: #808000; text-decoration-color: #808000\">'.'</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 ‚îÇ   ‚îÇ   ‚îÇ   </span>level += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>126 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _bootstrap._gcd_import(name[level:], package, level)                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 </span>_RELOADING = {}                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1206</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_gcd_import</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1178</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_find_and_load</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1149</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_find_and_load_unlocked</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">690</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_unlocked</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap_external&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">940</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">exec_module</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">241</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_with_frames_removed</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_tf_roberta.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">36</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  33 ‚îÇ   </span>TFSequenceClassifierOutput,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  34 ‚îÇ   </span>TFTokenClassifierOutput,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  35 </span>)                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>  36 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">...modeling_tf_utils</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> (                                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  37 ‚îÇ   </span>TFCausalLanguageModelingLoss,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  38 ‚îÇ   </span>TFMaskedLanguageModelingLoss,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  39 ‚îÇ   </span>TFModelInputType,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_tf_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">70</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  67 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  68 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> parse(tf.__version__) &gt;= parse(<span style=\"color: #808000; text-decoration-color: #808000\">\"2.11.0\"</span>):                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  69 ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">keras</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> backend <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> K                                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>  70 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">keras.engine</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> data_adapter                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  71 ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">keras.engine.keras_tensor</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> KerasTensor                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  72 ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">keras.saving.legacy</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> hdf5_format                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  73 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'keras.engine'</span>\n",
       "\n",
       "<span style=\"font-style: italic\">The above exception was the direct cause of the following exception:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3898610588.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/3898610588.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1231</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_handle_fromlist</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1163</span> in            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1160 ‚îÇ   ‚îÇ   ‚îÇ   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_module(name)                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1161 ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._class_to_module.keys():                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1162 ‚îÇ   ‚îÇ   ‚îÇ   </span>module = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._class_to_module[name])                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1163 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(module, name)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1164 ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1165 ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AttributeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"module {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">} has no attribute {</span>name<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1166 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1162</span> in            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1159 ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._modules:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1160 ‚îÇ   ‚îÇ   ‚îÇ   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_module(name)                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1161 ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._class_to_module.keys():                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1162 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>module = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._class_to_module[name])                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1163 ‚îÇ   ‚îÇ   ‚îÇ   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(module, name)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1164 ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1165 ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AttributeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"module {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">} has no attribute {</span>name<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1174</span> in            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_module</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1171 ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1172 ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> importlib.import_module(<span style=\"color: #808000; text-decoration-color: #808000\">\".\"</span> + module_name, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1173 ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1174 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1175 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Failed to import {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}.{</span>module_name<span style=\"color: #808000; text-decoration-color: #808000\">} because of the followin</span>  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1176 ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" traceback):\\n{</span>e<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1177 ‚îÇ   ‚îÇ   ‚îÇ   </span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">e</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Failed to import transformers.models.roberta.modeling_tf_roberta because of the following error <span style=\"font-weight: bold\">(</span>look\n",
       "up to see its traceback<span style=\"font-weight: bold\">)</span>:\n",
       "No module named <span style=\"color: #008000; text-decoration-color: #008000\">'keras.engine'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1172\u001b[0m in            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[92m_get_module\u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1169 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1170 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_module\u001b[0m(\u001b[96mself\u001b[0m, module_name: \u001b[96mstr\u001b[0m):                                              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1171 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1172 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m importlib.import_module(\u001b[33m\"\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m + module_name, \u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m)              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1173 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1174 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1175 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFailed to import \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m{\u001b[0mmodule_name\u001b[33m}\u001b[0m\u001b[33m because of the followin\u001b[0m  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11\u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/importlib/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m126\u001b[0m in \u001b[92mimport_module\u001b[0m                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m character != \u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m'\u001b[0m:                                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mbreak\u001b[0m                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mlevel += \u001b[94m1\u001b[0m                                                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m126 \u001b[2m‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m _bootstrap._gcd_import(name[level:], package, level)                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m127 \u001b[0m                                                                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m128 \u001b[0m                                                                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m129 \u001b[0m_RELOADING = {}                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m1206\u001b[0m in \u001b[92m_gcd_import\u001b[0m                                                \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m1178\u001b[0m in \u001b[92m_find_and_load\u001b[0m                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m1149\u001b[0m in \u001b[92m_find_and_load_unlocked\u001b[0m                                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m690\u001b[0m in \u001b[92m_load_unlocked\u001b[0m                                              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[33m<frozen importlib._bootstrap_external>\u001b[0m:\u001b[94m940\u001b[0m in \u001b[92mexec_module\u001b[0m                                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m241\u001b[0m in \u001b[92m_call_with_frames_removed\u001b[0m                                   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_tf_roberta.py\u001b[0m:\u001b[94m36\u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  33 \u001b[0m\u001b[2m‚îÇ   \u001b[0mTFSequenceClassifierOutput,                                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  34 \u001b[0m\u001b[2m‚îÇ   \u001b[0mTFTokenClassifierOutput,                                                              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  35 \u001b[0m)                                                                                         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m  36 \u001b[94mfrom\u001b[0m \u001b[4;96m.\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mmodeling_tf_utils\u001b[0m \u001b[94mimport\u001b[0m (                                                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  37 \u001b[0m\u001b[2m‚îÇ   \u001b[0mTFCausalLanguageModelingLoss,                                                         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  38 \u001b[0m\u001b[2m‚îÇ   \u001b[0mTFMaskedLanguageModelingLoss,                                                         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  39 \u001b[0m\u001b[2m‚îÇ   \u001b[0mTFModelInputType,                                                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_tf_utils.py\u001b[0m:\u001b[94m70\u001b[0m in \u001b[92m<module>\u001b[0m      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  67 \u001b[0m                                                                                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  68 \u001b[0m\u001b[94mif\u001b[0m parse(tf.__version__) >= parse(\u001b[33m\"\u001b[0m\u001b[33m2.11.0\u001b[0m\u001b[33m\"\u001b[0m):                                              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  69 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mkeras\u001b[0m \u001b[94mimport\u001b[0m backend \u001b[94mas\u001b[0m K                                                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m  70 \u001b[2m‚îÇ   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mkeras\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mengine\u001b[0m \u001b[94mimport\u001b[0m data_adapter                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  71 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mkeras\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mengine\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mkeras_tensor\u001b[0m \u001b[94mimport\u001b[0m KerasTensor                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  72 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mkeras\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96msaving\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mlegacy\u001b[0m \u001b[94mimport\u001b[0m hdf5_format                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  73 \u001b[0m\u001b[94melse\u001b[0m:                                                                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'keras.engine'\u001b[0m\n",
       "\n",
       "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
       "\n",
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/\u001b[0m\u001b[1;33m3898610588.py\u001b[0m:\u001b[94m5\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[3;31m'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/3898610588.py'\u001b[0m                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m1231\u001b[0m in \u001b[92m_handle_fromlist\u001b[0m                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1163\u001b[0m in            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[92m__getattr__\u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1160 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mvalue = \u001b[96mself\u001b[0m._get_module(name)                                                \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1161 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94melif\u001b[0m name \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._class_to_module.keys():                                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1162 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mmodule = \u001b[96mself\u001b[0m._get_module(\u001b[96mself\u001b[0m._class_to_module[name])                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1163 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mvalue = \u001b[96mgetattr\u001b[0m(module, name)                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1164 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1165 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAttributeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mmodule \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m has no attribute \u001b[0m\u001b[33m{\u001b[0mname\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1166 \u001b[0m                                                                                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1162\u001b[0m in            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[92m__getattr__\u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1159 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m name \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._modules:                                                         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1160 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mvalue = \u001b[96mself\u001b[0m._get_module(name)                                                \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1161 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94melif\u001b[0m name \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._class_to_module.keys():                                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1162 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mmodule = \u001b[96mself\u001b[0m._get_module(\u001b[96mself\u001b[0m._class_to_module[name])                        \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1163 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mvalue = \u001b[96mgetattr\u001b[0m(module, name)                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1164 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1165 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAttributeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mmodule \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m has no attribute \u001b[0m\u001b[33m{\u001b[0mname\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1174\u001b[0m in            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[92m_get_module\u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1171 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1172 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m importlib.import_module(\u001b[33m\"\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m + module_name, \u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m)              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1173 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1174 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1175 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFailed to import \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m{\u001b[0mmodule_name\u001b[33m}\u001b[0m\u001b[33m because of the followin\u001b[0m  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1176 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m traceback):\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m{\u001b[0me\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1177 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m) \u001b[94mfrom\u001b[0m \u001b[4;96me\u001b[0m                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mFailed to import transformers.models.roberta.modeling_tf_roberta because of the following error \u001b[1m(\u001b[0mlook\n",
       "up to see its traceback\u001b[1m)\u001b[0m:\n",
       "No module named \u001b[32m'keras.engine'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ids = tf.keras.layers.Input((MAX_LEN, ), dtype=tf.int32)\n",
    "att = tf.keras.layers.Input((MAX_LEN, ), dtype=tf.int32)\n",
    "tok = tf.keras.layers.Input((MAX_LEN, ), dtype=tf.int32)\n",
    "\n",
    "from transformers import TFRobertaModel\n",
    "config = RobertaConfig.from_pretrained('config-roberta-base.json')\n",
    "bert_model = TFRobertaModel.from_pretrained('pretrained-roberta-base.h5',config=config)\n",
    "x = bert_model(ids,attention_mask=att,token_type_ids=tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3a160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2f752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae5aabb",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Tokenizer details from HF (refer to this if you want to train own tokenizer)\n",
    "    - https://huggingface.co/docs/tokenizers/pipeline\n",
    "    \n",
    "    \n",
    "2. difference between autotokenizer.from_pretrained and specifictokenizer.from_pretrained\n",
    "    - gs: huggingface autotokenizer different from tokenizer\n",
    "    - https://github.com/huggingface/transformers/issues/5587\n",
    "    \n",
    "\n",
    "3. Why do we use offsets?\n",
    "    - gs: huggingface tokenizer offsets\n",
    "    -\n",
    "https://huggingface.co/transformers/v4.2.2/custom_datasets.html#:~:text=For%20each%20sub%2Dtoken%20returned,its%20corresponding%20label%20to%20%2D100%20.\n",
    "\n",
    "\n",
    "4.Difference between token ids and attention mask\n",
    "- [ref](https://jaketae.github.io/category/common-sense/#:~:text=Input%20IDs%20are%20obvious%3A%20these,where%20two%20sentences%20are%20given.)\n",
    "\n",
    "- input IDs are obvious: these are simply mappings between tokens and their respective IDs. The attention mask is to prevent the model from looking at padding tokens. The token type IDs are used typically in a next sentence prediction tasks, where two sentences are given.\n",
    "\n",
    "\n",
    "5. Error from using TFRobertaModel\n",
    "- No module named 'keras.engine'\n",
    "- Due to most latest version of tensorflow ... \n",
    "- downloaded the tf_model.h5 and saved in current directory, but does work\n",
    "\n",
    "6. What doe conv1d(filters=1,kernel_size=1) mean\n",
    "- This means that we are using 1 filters (output channel), kernel_size=1 means specifies the length of the 1D convolution window.\n",
    "- Convolution is applied on the second dimension. eg (4, 10, 128) -> convolution is applied on dim=1 (i.e shape=(10,)). \n",
    "    - To run sample, need to use the convolution weights\n",
    "\n",
    "7. When to use crossentropy loss and when to use binary cross entropy loss\n",
    "- gs: (pytorch cross entropy loss vs binarycrossentropy loss)\n",
    "- https://medium.com/dejunhuang/learning-day-57-practical-5-loss-function-crossentropyloss-vs-bceloss-in-pytorch-softmax-vs-bd866c8a0d23\n",
    "    - BinaryCrossEntropy() loss should be used for binary, crossentropy loss should be used for multi-class classification\n",
    "    - Reason:\n",
    "       - crossentropy loss will take as input a target y that can take on values (0,C), and expects the predictions to be of shape (batch_size, num_classes)\n",
    "        - BinaryCrossEntropy loss will take in as input a target y that can take on values (0,1), and expects the predictions to be of shape (batch_size, 1)\n",
    "        - CrossEntropy can be used for binary classification. \n",
    "           - Using sigmoid\n",
    "               - Final output is shape (batch_size, 2) because crossentropy loss needs to take in predictions with (bsize, num_classes)\n",
    "               - This means that we use one sigmoid for each 0 and 1 prediction before feeding it into CrossEntropy loss. \n",
    "               - But output probabilities will be meaningless. eg œÉ([-2.34, 3.45])=[8.79%, 96.9%] does not make sense\n",
    "           - Using softmax\n",
    "               Final output is also of shape (batch_size, 2) because crossentropy loss requires predictions with shape (bsize,num_classes)\n",
    "           - However, for binary classification where there are only two classes, the output from softmax tends to always be close to 0 and close to one. Eg. softmax([-2,34, 3,45])=[0.3%, 99.7%]\n",
    "           - So softmax is only suitable for multi-class classification.\n",
    "           \n",
    "- When to use binarycrossentropy, crossentroppy loss\n",
    "    - TLDR: BCE: multilabel, binary classification, CE: multiclass\n",
    "- https://stackoverflow.com/questions/59336899/which-loss-function-and-metrics-to-use-for-multi-label-classification-with-very\n",
    "    - gs: multi label classification binarycross entorpy\n",
    "- https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451\n",
    "    - gs: crossentropy loss for multi label classification\n",
    "- https://discuss.pytorch.org/t/what-kind-of-loss-is-better-to-use-in-multilabel-classification/32203\n",
    "    - gs: loss function for multi label classification pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dfffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
