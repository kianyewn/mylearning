{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3deee93a",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/cdeotte/tensorflow-roberta-0-705/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a3705ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c739f9",
   "metadata": {},
   "source": [
    "Roberta details\n",
    "<pre>\n",
    "  \"architectures\": [\n",
    "    \"RobertaForMaskedLM\"\n",
    "  ],\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"bos_token_id\": 0,\n",
    "  \"eos_token_id\": 2,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 768,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"layer_norm_eps\": 1e-05,\n",
    "  \"max_position_embeddings\": 514,\n",
    "  \"model_type\": \"roberta\",\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 12,\n",
    "  \"pad_token_id\": 1,\n",
    "  \"type_vocab_size\": 1,\n",
    "  \"vocab_size\": 50265\n",
    " </pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887ed48",
   "metadata": {},
   "source": [
    " Example vocab:\n",
    " <pre>\n",
    " {\"<s>\": 0, \"<pad>\": 1, \"</s>\": 2, \"<unk>\": 3, \".\": 4, \"Ġthe\": 5, \",\": 6, \"Ġto\": 7, \"Ġand\": 8, \"Ġof\": 9, \"Ġa\": 10, \"Ġin\": 11, \"-\": 12, \"Ġfor\": 13, \"Ġthat\": 14, \"Ġon\": 15, \"Ġis\": 16, \"âĢ\": 17, \"'s\": 18, \"Ġwith\": 19, \"ĠThe\": 20, \"Ġwas\": 21, \"Ġ\\\"\": 22, \"Ġat\": 23, \"Ġit\": 24, \"Ġas\": 25, \"Ġsaid\": 26, \"Ļ\": 27, \"Ġbe\": 28, \"s\": 29, \"Ġby\": 30, \"Ġfrom\": 31, \"Ġare\": 32, \"Ġhave\": 33, \"Ġhas\": 34, \":\": 35, \"Ġ(\": 36, \"Ġhe\": 37, \"ĠI\": 38, \"Ġhis\": 39, \"Ġwill\": 40, \"Ġan\": 41, \"Ġthis\": 42, \")\": 43, \"ĠâĢ\": 44, \"Ġnot\": 45, \"Ŀ\": 46, \"Ġyou\": 47, \"ľ\": 48, \"Ġtheir\": 49, \"Ġor\": 50, \"Ġthey\": 51, \"Ġwe\": 52, \"Ġbut\": 53, \"Ġwho\": 54, \"Ġmore\": 55, \"Ġhad\": 56\n",
    " </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roberta special tokens\n",
    "# - ['<s>', '</s>', '<unk>', '<pad>', '<mask>']\n",
    "\n",
    "special token ids\n",
    "[0, 2, 3, 1, 50264]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26069e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 'x', 2, 2, 'y', 2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.build_inputs_with_special_tokens(['x'], ['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2328e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '<unk>', '<pad>', '<mask>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d52ad79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 1, 50264]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e88a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)olve/main/vocab.json: 100%|█| 899k/899k [00:0\n",
      "Downloading (…)olve/main/merges.txt: 100%|█| 456k/456k [00:0\n",
      "Downloading (…)lve/main/config.json: 100%|█| 481/481 [00:00<\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d0e88bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 22173, 2], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27e8ec",
   "metadata": {},
   "source": [
    "For some reason, roberta tokenizer from pretrained is different from directly calling ByteLevelBPETokenizer\n",
    "eg, ID for 'positive' is 22173 in autotokenizer, but 1313 in ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "797d7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "# does not work\n",
    "# tokenizers.ByteLevelBPETokenizer.from_pretrained('roberta-base')\n",
    "ROBERTA_PATH = \"/Users/kianyewngieng/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68\"\n",
    "TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab=f\"{ROBERTA_PATH}/vocab.json\", \n",
    "    merges=f\"{ROBERTA_PATH}/merges.txt\", \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "tokenizer = TOKENIZER\n",
    "\n",
    "sentiment_id = {'positive': 1313, 'negative':2430, 'neutral': 7974}\n",
    "\n",
    "train = pd.read_csv('../data/tweet-sentiment-extraction/train.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e9f9165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape # 24k sample size for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c1d77013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63f450",
   "metadata": {},
   "source": [
    "##  Tokenize train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb755052",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 96\n",
    "\n",
    "ct = train.shape[0]\n",
    "input_ids = np.ones((ct, MAX_LEN), dtype='int32')\n",
    "attention_mask = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "token_type_ids = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "start_tokens = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "end_tokens = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "\n",
    "for k in range(train.shape[0]):\n",
    "    # adds a space in front\n",
    "    text1  = \" \" + \" \".join(train.loc[k, 'text'].split())\n",
    "    text2 = \" \".join(train.loc[k, 'selected_text'].split())\n",
    "    # return start index for the substring\n",
    "    idx = text1.find(text2)\n",
    "    chars = np.zeros((len(text1)))\n",
    "    \n",
    "    # token_ids for the sample\n",
    "    chars[idx:idx+len(text2)] = 1\n",
    "    # fill up the \n",
    "    if text1[idx-1]==' ':\n",
    "        chars[idx-1] = 1\n",
    "    \n",
    "    enc = tokenizer.encode(text1)\n",
    "    \n",
    "    # id_offsets\n",
    "    # For each sub-token returned by the tokenizer, \n",
    "    # the offset mapping gives us a tuple indicating the \n",
    "    # sub-token’s start position and end position relative to\n",
    "    # the original token it was split from. \n",
    "    # That means that if the first position in the tuple is \n",
    "    # anything other than 0, we will set its corresponding label to -100. \n",
    "    # While we’re at it, we can also set labels to -100 \n",
    "    # if the second position of the offset mapping is 0, \n",
    "    # since this means it must be a special token like [PAD] or [CLS].\n",
    "    offsets = []\n",
    "    idx = 0\n",
    "    for t in enc.ids:\n",
    "        w = tokenizer.decode([t])\n",
    "        offsets.append([idx, idx+len(w)])\n",
    "        idx += len(w)\n",
    "        \n",
    "    # START END TOKENS\n",
    "    toks = []\n",
    "    for i, (a,b) in enumerate(offsets):\n",
    "        sm = np.sum(chars[a:b])\n",
    "        if sm>0: \n",
    "            toks.append(i)\n",
    "            \n",
    "    s_tok = sentiment_id[train.loc[k, 'sentiment']]\n",
    "    input_ids[k, :len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask[k, :len(enc.ids)+5] = 1\n",
    "    if len(toks)>0:\n",
    "        start_tokens[k, toks[0]+1] = 1\n",
    "        end_tokens[k, toks[-1] + 1] = 1\n",
    "    \n",
    "#     if k == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fb4e4ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3), (3, 8), (8, 11), (11, 20), (20, 23), (23, 26)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6a2c0ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' my boss is bullying me...'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bdd29489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[127, 3504, 16, 11902, 162, 734]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ad51e6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' my boss is bullying me...'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e3f61cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bullying me'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21baaf11",
   "metadata": {},
   "source": [
    "##### tokenizer does not split on beginning of sentence \" \"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "95666fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[127, 3504, 16, 11902, 162, 734]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text1).ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5ea611bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my boss is bullying me...'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1_v2 = text1[1:]\n",
    "text1_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ee68808d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[127, 3504, 16, 11902, 162, 734]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text1_v2).ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4a023680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' my'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([127])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196d4a7",
   "metadata": {},
   "source": [
    "/end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a7039f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,   127,  3504,    16, 11902,   162,   734,     2,     2,\n",
       "        2430,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1], dtype=int32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9efcae5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "03d8e492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3], [3, 8], [8, 11], [11, 20], [20, 23], [23, 26]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d393b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "893935b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_tokens[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b7ecf760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_tokens[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "   s_tok = sentiment_id[train.loc[k,'sentiment']]\n",
    "    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask[k,:len(enc.ids)+5] = 1\n",
    "    if len(toks)>0:\n",
    "        start_tokens[k,toks[0]+1] = 1\n",
    "        end_tokens[k,toks[-1]+1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4745e92e",
   "metadata": {},
   "source": [
    "Now we arrive at a common obstacle with using pre-trained models for token-level classification: many of the tokens in the W-NUT corpus are not in DistilBert’s vocabulary. Bert and many models like it use a method called WordPiece Tokenization, meaning that single words are split into multiple tokens such that each token is likely to be in the vocabulary. For example, DistilBert’s tokenizer would split the Twitter handle @huggingface into the tokens ['@', 'hugging', '##face']. This is a problem for us because we have exactly one tag per token. If the tokenizer splits a token into multiple sub-tokens, then we will end up with a mismatch between our tokens and our labels.\n",
    "\n",
    "One way to handle this is to only train on the tag labels for the first subtoken of a split token. We can do this in 🤗 Transformers by setting the labels we wish to ignore to -100. In the example above, if the label for @HuggingFace is 3 (indexing B-corporation), we would set the labels of ['@', 'hugging', '##face'] to [3, -100, -100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c6228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2029392",
   "metadata": {},
   "source": [
    "### tokenize test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b462a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/tweet-sentiment-extraction/test.csv').fillna('')\n",
    "ct = test.shape[0]\n",
    "input_ids = np.ones((ct, MAX_LEN), dtype='int32')\n",
    "attention_mask_t = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "token_type_ids_t = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "\n",
    "for k in range(test.shape[0]):\n",
    "    text1 = \" \" + \" \".join(test.loc[k, 'text'].split())\n",
    "    enc = tokenizer.encode(text1)\n",
    "    s_tok = sentiment_id[test.loc[k,'sentiment']]\n",
    "    input_ids[k, :len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask_t[k, len(enc.ids)+5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372b23bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3534, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c9ad4b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "bert_model = AutoModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f747280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "input_ids = torch.from_numpy(input_ids) # , dtype=torch.int64)\n",
    "attention_mask = torch.from_numpy(attention_mask_t) # , dtype=torch.int64)\n",
    "token_type_ids = torch.from_numpy(token_type_ids_t) # , dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54a8bfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3534, 96])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b507a03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3534, 96])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cac3857b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3534, 96])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b694c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce600475",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "61ad2fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fef6554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bert_model(input_ids=input_ids[[2]], \n",
    "           attention_mask=attention_mask[[2]],\n",
    "           token_type_ids=token_type_ids[[2]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6edd9aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0518,  0.0734, -0.0339,  ..., -0.1223, -0.0407, -0.0231],\n",
       "         [-0.0561,  0.0678, -0.0304,  ..., -0.1155, -0.0411, -0.0226],\n",
       "         [-0.0516,  0.0701, -0.0300,  ..., -0.1202, -0.0383, -0.0211],\n",
       "         ...,\n",
       "         [-0.0671,  0.0620, -0.0265,  ..., -0.1117, -0.0480, -0.0200],\n",
       "         [-0.0671,  0.0620, -0.0265,  ..., -0.1117, -0.0480, -0.0200],\n",
       "         [-0.0671,  0.0620, -0.0265,  ..., -0.1117, -0.0480, -0.0200]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0123, -0.2211, -0.2488, -0.0714,  0.1332,  0.1888,  0.2768, -0.1189,\n",
       "         -0.0821, -0.1937,  0.2648,  0.0115, -0.1351,  0.0860, -0.1485,  0.4940,\n",
       "          0.2344, -0.4982,  0.0320, -0.0089, -0.2283,  0.0748,  0.4725,  0.3132,\n",
       "          0.1108,  0.0729, -0.1433, -0.0355,  0.1917,  0.2477,  0.2759,  0.0387,\n",
       "          0.1500,  0.2116, -0.2434,  0.0748, -0.3380, -0.0159,  0.2932, -0.1931,\n",
       "         -0.0731,  0.1764,  0.2287, -0.1756, -0.1225,  0.4253,  0.2291,  0.0461,\n",
       "         -0.1226, -0.0680, -0.3591,  0.3606,  0.3015,  0.1936, -0.0681,  0.0261,\n",
       "         -0.1251,  0.2660, -0.0809, -0.0868, -0.1245, -0.2239, -0.0244, -0.0313,\n",
       "          0.0291, -0.1347,  0.0924, -0.1853, -0.1391,  0.0338, -0.1186,  0.1235,\n",
       "          0.1636, -0.2875, -0.2688,  0.0582, -0.6159, -0.1221,  0.3070,  0.4265,\n",
       "         -0.1136,  0.2278,  0.0246,  0.2445,  0.0007, -0.0626, -0.0184, -0.1076,\n",
       "          0.1857,  0.2726, -0.2103, -0.4478,  0.0464,  0.0108, -0.1277, -0.0089,\n",
       "          0.0033, -0.0987, -0.1552, -0.1729,  0.0786, -0.2734, -0.1339,  0.2644,\n",
       "         -0.0122, -0.2451, -0.0413,  0.3109,  0.0427, -0.1418, -0.1803,  0.4224,\n",
       "          0.3370,  0.0324, -0.0031,  0.1848,  0.0846, -0.2919,  0.4293, -0.3464,\n",
       "         -0.0007, -0.0981,  0.1490,  0.1370, -0.2160,  0.2666,  0.1411,  0.2766,\n",
       "          0.1725,  0.0802, -0.0331,  0.1242, -0.1366,  0.1387,  0.1902,  0.0852,\n",
       "         -0.0176, -0.3202, -0.2702,  0.2725,  0.3578,  0.1290, -0.0159,  0.2337,\n",
       "          0.1073,  0.2086,  0.1570, -0.4195,  0.0714,  0.3735,  0.1065,  0.1668,\n",
       "         -0.1030, -0.2955, -0.2753, -0.0963,  0.0375, -0.3624, -0.1080,  0.3748,\n",
       "         -0.0106, -0.0270, -0.1550, -0.2035, -0.0337, -0.1310,  0.0125,  0.0977,\n",
       "         -0.0666, -0.4218, -0.0987, -0.5267, -0.1254,  0.2443, -0.2959,  0.2589,\n",
       "         -0.3306,  0.1106,  0.4184,  0.0088, -0.0032, -0.2124,  0.0136,  0.0782,\n",
       "          0.3204,  0.2433, -0.3969,  0.0877,  0.1317,  0.2521,  0.1383, -0.0156,\n",
       "         -0.1406,  0.1678, -0.2274,  0.1871, -0.2498,  0.1928, -0.2434, -0.2249,\n",
       "          0.2930, -0.4090, -0.0813,  0.0977,  0.2843,  0.0321, -0.0811, -0.1181,\n",
       "          0.1047,  0.1944,  0.1390, -0.4024,  0.2827,  0.0062, -0.0168, -0.0434,\n",
       "          0.1476,  0.2063,  0.1479, -0.3847, -0.1149,  0.1406,  0.2581, -0.2796,\n",
       "          0.1615, -0.2909, -0.4047, -0.1138,  0.2240,  0.2828,  0.1631, -0.2598,\n",
       "          0.1473, -0.1264, -0.4344, -0.3872, -0.1250,  0.2810,  0.1891,  0.1634,\n",
       "          0.2514,  0.0770,  0.1290,  0.1402,  0.1502, -0.1716,  0.1613, -0.3850,\n",
       "         -0.0879, -0.2885, -0.1816, -0.2384,  0.4364, -0.2454,  0.2339,  0.4111,\n",
       "         -0.2963, -0.1205,  0.1274,  0.1071,  0.1022, -0.1209,  0.2213,  0.1707,\n",
       "         -0.1190,  0.2573,  0.0324,  0.2638,  0.1421,  0.0998,  0.1383,  0.1368,\n",
       "         -0.1536,  0.0801,  0.0240, -0.0344, -0.2543, -0.1600,  0.2540, -0.0423,\n",
       "          0.0492, -0.1596, -0.0876, -0.0140,  0.4245, -0.3842,  0.2498,  0.0843,\n",
       "          0.1281, -0.2650, -0.1868,  0.0841,  0.2091, -0.4231,  0.0604,  0.1548,\n",
       "          0.0875,  0.1762,  0.2654, -0.0261, -0.1700,  0.4879, -0.1671, -0.1490,\n",
       "          0.2640, -0.2773, -0.2826,  0.2633, -0.0109,  0.3118,  0.0818,  0.0236,\n",
       "          0.1132, -0.6287,  0.0601, -0.4581, -0.0142,  0.0096, -0.0999, -0.2373,\n",
       "          0.1255,  0.2874, -0.2667, -0.0611,  0.2151,  0.0509, -0.0867,  0.4866,\n",
       "         -0.0191,  0.2049, -0.0812,  0.2736, -0.2376,  0.2616, -0.2633, -0.1022,\n",
       "          0.0413,  0.0928,  0.0744, -0.0527, -0.3820,  0.2585, -0.0519, -0.0476,\n",
       "         -0.0520,  0.1333, -0.0160,  0.0134,  0.0652,  0.3586,  0.2593, -0.0379,\n",
       "         -0.3834,  0.0054, -0.1089,  0.0779,  0.0219,  0.0155,  0.4498, -0.1010,\n",
       "         -0.0008, -0.1395,  0.2790,  0.2029,  0.1419,  0.1574,  0.0446,  0.1669,\n",
       "         -0.0631, -0.0095, -0.1613, -0.2443, -0.3073,  0.2241, -0.2744, -0.1847,\n",
       "          0.1657,  0.1711, -0.1124,  0.1274,  0.3311,  0.0954, -0.1504,  0.2298,\n",
       "         -0.1148,  0.0961,  0.3064, -0.0319,  0.1915,  0.5452,  0.2289, -0.3804,\n",
       "         -0.0516, -0.2337, -0.0130,  0.2713, -0.1502,  0.1728,  0.4125,  0.2949,\n",
       "          0.4777, -0.0020, -0.1265,  0.1145,  0.2383,  0.0243, -0.1914, -0.1697,\n",
       "          0.2784,  0.0463, -0.1038,  0.0175, -0.1328,  0.0502, -0.1337, -0.4143,\n",
       "          0.0609,  0.2092, -0.4829,  0.1412, -0.3402,  0.0138, -0.2112,  0.2318,\n",
       "         -0.2924, -0.1388,  0.3893, -0.0891,  0.0456, -0.2107, -0.1778,  0.0420,\n",
       "          0.0155,  0.0050, -0.0302,  0.3415, -0.1332,  0.0264,  0.0267,  0.2108,\n",
       "         -0.0685,  0.2043,  0.0397, -0.1349, -0.4266,  0.1898, -0.2123, -0.4077,\n",
       "         -0.3653,  0.3804, -0.1344, -0.2491, -0.2218, -0.2585,  0.0482,  0.1580,\n",
       "          0.4296, -0.3762, -0.0611,  0.5144, -0.0295, -0.1976,  0.2666,  0.2200,\n",
       "         -0.3347,  0.3940,  0.2973, -0.0564,  0.0060,  0.5350,  0.1273,  0.2151,\n",
       "         -0.2190,  0.4611, -0.2472,  0.3230, -0.1787, -0.2292, -0.2483, -0.0252,\n",
       "          0.3359,  0.1843, -0.4414, -0.1097,  0.0461,  0.3414, -0.3617, -0.0901,\n",
       "          0.0200, -0.3417,  0.0803,  0.1014,  0.2095, -0.4185, -0.0560,  0.3954,\n",
       "         -0.3497,  0.1017,  0.3212,  0.0757,  0.3683, -0.0200, -0.0374,  0.0768,\n",
       "         -0.2699, -0.0426,  0.1399,  0.5695,  0.1249, -0.4081,  0.1045,  0.2615,\n",
       "         -0.1397,  0.3310, -0.1062, -0.0796,  0.3004, -0.0607,  0.1509, -0.0778,\n",
       "         -0.2638, -0.3361,  0.3723, -0.2383, -0.0886, -0.1908, -0.0851, -0.1461,\n",
       "          0.0339, -0.4041,  0.3699,  0.1584, -0.2190, -0.0798, -0.0973, -0.1521,\n",
       "         -0.2230, -0.2847,  0.4314, -0.1698, -0.4677,  0.2720,  0.0503,  0.3558,\n",
       "          0.0152,  0.1344, -0.0559,  0.1434,  0.0989, -0.1175,  0.2725,  0.1042,\n",
       "         -0.5814, -0.1195, -0.2533,  0.0660,  0.2292, -0.3507,  0.0248,  0.0262,\n",
       "          0.1356,  0.0533, -0.1111, -0.0840,  0.3809,  0.2502,  0.2593,  0.1451,\n",
       "          0.1964, -0.0123, -0.3292,  0.0433,  0.0654, -0.1813,  0.4353, -0.1057,\n",
       "         -0.4109, -0.0843,  0.4212,  0.1260, -0.0670, -0.0483,  0.2070,  0.1252,\n",
       "         -0.0790,  0.1463, -0.0595, -0.1538, -0.1353,  0.0992, -0.2283,  0.0622,\n",
       "         -0.1935, -0.0074, -0.2159,  0.0039, -0.2147,  0.2779, -0.3649,  0.1137,\n",
       "          0.0511,  0.3079, -0.3670, -0.1680, -0.0439,  0.1968,  0.2426,  0.3692,\n",
       "          0.0359,  0.0690, -0.1754, -0.2597,  0.0510, -0.2112,  0.1192,  0.0780,\n",
       "          0.2469, -0.3326, -0.1827,  0.1765, -0.0543, -0.1858,  0.4512,  0.2421,\n",
       "          0.2432,  0.0162,  0.2720,  0.0113, -0.2364, -0.1371, -0.2827,  0.0818,\n",
       "         -0.0985, -0.0734, -0.0468, -0.0981, -0.1973, -0.1372,  0.1311,  0.1060,\n",
       "         -0.0018, -0.0737, -0.0090, -0.3121,  0.3340,  0.0296,  0.0570, -0.0233,\n",
       "          0.0554, -0.1893,  0.2369,  0.2406,  0.0792, -0.1807, -0.0392, -0.3295,\n",
       "         -0.3712,  0.0547,  0.1358,  0.1185, -0.1059, -0.2729,  0.0182, -0.0917,\n",
       "          0.1945,  0.0315, -0.1698, -0.1007, -0.0653, -0.0703,  0.0975, -0.1866,\n",
       "         -0.1975, -0.0914, -0.0575, -0.0761,  0.3706, -0.0611,  0.3221, -0.1810,\n",
       "         -0.0058, -0.1492,  0.1580, -0.0768,  0.0516,  0.2546, -0.4335, -0.1423,\n",
       "         -0.0224, -0.2343, -0.1289, -0.0472, -0.0288,  0.2363, -0.3360,  0.2141,\n",
       "         -0.1182,  0.1866, -0.0252, -0.2552, -0.1286,  0.0141,  0.2666, -0.3325,\n",
       "         -0.2463, -0.3173, -0.1323, -0.0855, -0.2820,  0.4570, -0.1388, -0.1039,\n",
       "          0.0456,  0.4450,  0.2067,  0.1497,  0.2278, -0.0560,  0.0133,  0.1498,\n",
       "         -0.4891,  0.2088, -0.2832, -0.1524,  0.0295,  0.1311, -0.0359,  0.0282,\n",
       "         -0.1601, -0.0472,  0.2138, -0.4119, -0.0433,  0.2638,  0.1166, -0.2440,\n",
       "          0.0295,  0.1334,  0.4004,  0.1538, -0.2137,  0.1328, -0.3361, -0.0126,\n",
       "         -0.1901, -0.3184,  0.1796, -0.0845,  0.0740, -0.0960, -0.3148,  0.2281,\n",
       "         -0.0375, -0.0561,  0.4384,  0.0057, -0.0627,  0.1206,  0.0217,  0.0575,\n",
       "         -0.0932,  0.2407,  0.1936, -0.2923,  0.1618, -0.1109, -0.0719, -0.1055]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aba9988b",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0064f94e",
   "metadata": {},
   "source": [
    "### Comparing Conv1d in pytorch and tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c0caa1c4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_1580/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">71761320.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_1580/71761320.py'</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">conv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">313</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 │   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 311 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 312 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 313 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._conv_forward(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 314 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 315 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 316 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">Conv2d</span>(_ConvNd):                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">conv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">309</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_conv_forward</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 306 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.conv1d(F.pad(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reversed_padding_repeated_twice, mode=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">sel</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 307 │   │   │   │   │   │   │   </span>weight, bias, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.stride,                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 308 │   │   │   │   │   │   │   </span>_single(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 309 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.conv1d(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, weight, bias, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.stride,                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 │   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 311 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 312 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Given <span style=\"color: #808000; text-decoration-color: #808000\">groups</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, weight of size <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>, expected input<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">]</span> to have <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> channels, but got \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span> channels instead\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_1580/\u001b[0m\u001b[1;33m71761320.py\u001b[0m:\u001b[94m10\u001b[0m in \u001b[92m<module>\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_1580/71761320.py'\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mconv.py\u001b[0m:\u001b[94m313\u001b[0m in \u001b[92mforward\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 310 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.padding, \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 311 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 312 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 313 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._conv_forward(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 314 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 315 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 316 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mConv2d\u001b[0m(_ConvNd):                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mconv.py\u001b[0m:\u001b[94m309\u001b[0m in \u001b[92m_conv_forward\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 306 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m F.conv1d(F.pad(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m._reversed_padding_repeated_twice, mode=\u001b[96msel\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 307 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mweight, bias, \u001b[96mself\u001b[0m.stride,                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 308 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m_single(\u001b[94m0\u001b[0m), \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 309 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.conv1d(\u001b[96minput\u001b[0m, weight, bias, \u001b[96mself\u001b[0m.stride,                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 310 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.padding, \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 311 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 312 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mGiven \u001b[33mgroups\u001b[0m=\u001b[1;36m1\u001b[0m, weight of size \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m, expected input\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m96\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m to have \u001b[1;36m768\u001b[0m channels, but got \n",
       "\u001b[1;36m96\u001b[0m channels instead\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lhs = x.last_hidden_state\n",
    "import torch.nn as nn\n",
    "\n",
    "# weihghts does not match the timestep dimension\n",
    "x1 = nn.Dropout(0.2)(lhs)\n",
    "convx1 = nn.Conv1d(in_channels = 768, \n",
    "               out_channels=1,\n",
    "               kernel_size=1,\n",
    "               stride=1)\n",
    "x1 = convx1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "931df890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 1])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convx1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5a667ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 768])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0b1aafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(4, 10, 128)\n",
    "tf_conv = tf.keras.layers.Conv1D(1,1)\n",
    "tf_out = tf_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "79613dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4542f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_conv = nn.Conv1d(128, 1, 1)\n",
    "nn_conv.weight = nn.Parameter(torch.tensor(tf_conv.get_weights()[0], dtype=torch.float))\n",
    "nn_out = nn_conv(torch.tensor(x, dtype=torch.float).transpose(-2,-1)).transpose(-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ae8156a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a35c65f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10, 1)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f90b642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_out = nn_out.detach().numpy()\n",
    "tf_out = tf_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "36284ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.1552157 ],\n",
       "       [-2.577402  ],\n",
       "       [-0.85579425],\n",
       "       [-1.0808017 ],\n",
       "       [-0.09038931],\n",
       "       [ 1.447653  ],\n",
       "       [ 0.4062286 ],\n",
       "       [ 0.38171047],\n",
       "       [-0.02897149],\n",
       "       [-0.73734987]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a654fbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.2065475 ],\n",
       "       [-2.5260706 ],\n",
       "       [-0.8044631 ],\n",
       "       [-1.0294701 ],\n",
       "       [-0.0390582 ],\n",
       "       [ 1.4989845 ],\n",
       "       [ 0.45756042],\n",
       "       [ 0.43304208],\n",
       "       [ 0.02236023],\n",
       "       [-0.6860184 ]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fea8cabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0fbf6413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10, 1])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4b03fb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10, 1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "input_shape = (4, 10, 128)\n",
    "x = tf.random.normal(input_shape)\n",
    "conv = tf.keras.layers.Conv1D(1,1)\n",
    "out = conv(x)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d09d5df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51cb8cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10, 128])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62b0ae2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e991082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10, 128])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5e8eee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c80947a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.3941005], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bcc7a326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.get_weights()[0].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c443641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a3077a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39410055"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(conv.get_weights()[0].squeeze() * x[0,0, :]).numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8646645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.271212"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,:].numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20aa2fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09586884"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,:].numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9c03c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08947609"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:, 0].numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a305fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0,:, 0].numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a76f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7878d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b548c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ef977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c96eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2821e029",
   "metadata": {},
   "source": [
    "### Build roberta model (Tensorflow) HAS BUG regarding tensorflow latest versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "70899e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3776479232.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/3776479232.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'keras.engine'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/\u001b[0m\u001b[1;33m3776479232.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/3776479232.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'keras.engine'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.engine import data_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "59fd0714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1791973581.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/1791973581.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'keras.engine'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/\u001b[0m\u001b[1;33m1791973581.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/1791973581.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'keras.engine'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow.python.keras as keras\n",
    "from keras.engine import data_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bcc5cb47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1172</span> in            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_module</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1169 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1170 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_module</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module_name: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1171 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1172 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> importlib.import_module(<span style=\"color: #808000; text-decoration-color: #808000\">\".\"</span> + module_name, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1173 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1174 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1175 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Failed to import {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}.{</span>module_name<span style=\"color: #808000; text-decoration-color: #808000\">} because of the followin</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/importlib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">126</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">import_module</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> character != <span style=\"color: #808000; text-decoration-color: #808000\">'.'</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 │   │   │   </span>level += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>126 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _bootstrap._gcd_import(name[level:], package, level)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 </span>_RELOADING = {}                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1206</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_gcd_import</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1178</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_find_and_load</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1149</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_find_and_load_unlocked</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">690</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_unlocked</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap_external&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">940</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">exec_module</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">241</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_with_frames_removed</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_tf_roberta.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">36</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  33 │   </span>TFSequenceClassifierOutput,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  34 │   </span>TFTokenClassifierOutput,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  35 </span>)                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  36 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">...modeling_tf_utils</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> (                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  37 │   </span>TFCausalLanguageModelingLoss,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  38 │   </span>TFMaskedLanguageModelingLoss,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  39 │   </span>TFModelInputType,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_tf_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">70</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  67 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  68 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> parse(tf.__version__) &gt;= parse(<span style=\"color: #808000; text-decoration-color: #808000\">\"2.11.0\"</span>):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  69 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">keras</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> backend <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> K                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  70 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">keras.engine</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> data_adapter                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  71 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">keras.engine.keras_tensor</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> KerasTensor                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  72 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">keras.saving.legacy</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> hdf5_format                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  73 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'keras.engine'</span>\n",
       "\n",
       "<span style=\"font-style: italic\">The above exception was the direct cause of the following exception:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3898610588.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/3898610588.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;frozen importlib._bootstrap&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1231</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_handle_fromlist</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1163</span> in            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1160 │   │   │   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_module(name)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1161 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._class_to_module.keys():                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1162 │   │   │   </span>module = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._class_to_module[name])                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1163 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(module, name)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1164 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1165 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AttributeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"module {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">} has no attribute {</span>name<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1166 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1162</span> in            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1159 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._modules:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1160 │   │   │   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_module(name)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1161 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._class_to_module.keys():                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1162 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._class_to_module[name])                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1163 │   │   │   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(module, name)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1164 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1165 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AttributeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"module {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">} has no attribute {</span>name<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.11/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1174</span> in            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_module</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1171 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1172 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> importlib.import_module(<span style=\"color: #808000; text-decoration-color: #808000\">\".\"</span> + module_name, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1173 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1174 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1175 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Failed to import {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}.{</span>module_name<span style=\"color: #808000; text-decoration-color: #808000\">} because of the followin</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1176 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" traceback):\\n{</span>e<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1177 │   │   │   </span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">e</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Failed to import transformers.models.roberta.modeling_tf_roberta because of the following error <span style=\"font-weight: bold\">(</span>look\n",
       "up to see its traceback<span style=\"font-weight: bold\">)</span>:\n",
       "No module named <span style=\"color: #008000; text-decoration-color: #008000\">'keras.engine'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1172\u001b[0m in            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_get_module\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1169 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1170 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_module\u001b[0m(\u001b[96mself\u001b[0m, module_name: \u001b[96mstr\u001b[0m):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1171 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1172 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m importlib.import_module(\u001b[33m\"\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m + module_name, \u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1173 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1174 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1175 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFailed to import \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m{\u001b[0mmodule_name\u001b[33m}\u001b[0m\u001b[33m because of the followin\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/importlib/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m126\u001b[0m in \u001b[92mimport_module\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m character != \u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m'\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   │   │   \u001b[0mlevel += \u001b[94m1\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m126 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _bootstrap._gcd_import(name[level:], package, level)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m127 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m_RELOADING = {}                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m1206\u001b[0m in \u001b[92m_gcd_import\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m1178\u001b[0m in \u001b[92m_find_and_load\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m1149\u001b[0m in \u001b[92m_find_and_load_unlocked\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m690\u001b[0m in \u001b[92m_load_unlocked\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<frozen importlib._bootstrap_external>\u001b[0m:\u001b[94m940\u001b[0m in \u001b[92mexec_module\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m241\u001b[0m in \u001b[92m_call_with_frames_removed\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_tf_roberta.py\u001b[0m:\u001b[94m36\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  33 \u001b[0m\u001b[2m│   \u001b[0mTFSequenceClassifierOutput,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  34 \u001b[0m\u001b[2m│   \u001b[0mTFTokenClassifierOutput,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  35 \u001b[0m)                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  36 \u001b[94mfrom\u001b[0m \u001b[4;96m.\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mmodeling_tf_utils\u001b[0m \u001b[94mimport\u001b[0m (                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  37 \u001b[0m\u001b[2m│   \u001b[0mTFCausalLanguageModelingLoss,                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  38 \u001b[0m\u001b[2m│   \u001b[0mTFMaskedLanguageModelingLoss,                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  39 \u001b[0m\u001b[2m│   \u001b[0mTFModelInputType,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_tf_utils.py\u001b[0m:\u001b[94m70\u001b[0m in \u001b[92m<module>\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  67 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  68 \u001b[0m\u001b[94mif\u001b[0m parse(tf.__version__) >= parse(\u001b[33m\"\u001b[0m\u001b[33m2.11.0\u001b[0m\u001b[33m\"\u001b[0m):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  69 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mkeras\u001b[0m \u001b[94mimport\u001b[0m backend \u001b[94mas\u001b[0m K                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  70 \u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mkeras\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mengine\u001b[0m \u001b[94mimport\u001b[0m data_adapter                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  71 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mkeras\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mengine\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mkeras_tensor\u001b[0m \u001b[94mimport\u001b[0m KerasTensor                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  72 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mkeras\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96msaving\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mlegacy\u001b[0m \u001b[94mimport\u001b[0m hdf5_format                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  73 \u001b[0m\u001b[94melse\u001b[0m:                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'keras.engine'\u001b[0m\n",
       "\n",
       "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/\u001b[0m\u001b[1;33m3898610588.py\u001b[0m:\u001b[94m5\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/q4/s7bw96810896_5s4r65jl0780000gn/T/ipykernel_81569/3898610588.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<frozen importlib._bootstrap>\u001b[0m:\u001b[94m1231\u001b[0m in \u001b[92m_handle_fromlist\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1163\u001b[0m in            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__getattr__\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1160 \u001b[0m\u001b[2m│   │   │   \u001b[0mvalue = \u001b[96mself\u001b[0m._get_module(name)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1161 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m name \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._class_to_module.keys():                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1162 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodule = \u001b[96mself\u001b[0m._get_module(\u001b[96mself\u001b[0m._class_to_module[name])                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1163 \u001b[2m│   │   │   \u001b[0mvalue = \u001b[96mgetattr\u001b[0m(module, name)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1165 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAttributeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mmodule \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m has no attribute \u001b[0m\u001b[33m{\u001b[0mname\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1166 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1162\u001b[0m in            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__getattr__\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1159 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m name \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._modules:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1160 \u001b[0m\u001b[2m│   │   │   \u001b[0mvalue = \u001b[96mself\u001b[0m._get_module(name)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1161 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m name \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._class_to_module.keys():                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1162 \u001b[2m│   │   │   \u001b[0mmodule = \u001b[96mself\u001b[0m._get_module(\u001b[96mself\u001b[0m._class_to_module[name])                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1163 \u001b[0m\u001b[2m│   │   │   \u001b[0mvalue = \u001b[96mgetattr\u001b[0m(module, name)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1165 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAttributeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mmodule \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m has no attribute \u001b[0m\u001b[33m{\u001b[0mname\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1174\u001b[0m in            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_get_module\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1171 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1172 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m importlib.import_module(\u001b[33m\"\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m + module_name, \u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1173 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1174 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1175 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFailed to import \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m{\u001b[0mmodule_name\u001b[33m}\u001b[0m\u001b[33m because of the followin\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1176 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m traceback):\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m{\u001b[0me\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1177 \u001b[0m\u001b[2m│   │   │   \u001b[0m) \u001b[94mfrom\u001b[0m \u001b[4;96me\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mFailed to import transformers.models.roberta.modeling_tf_roberta because of the following error \u001b[1m(\u001b[0mlook\n",
       "up to see its traceback\u001b[1m)\u001b[0m:\n",
       "No module named \u001b[32m'keras.engine'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ids = tf.keras.layers.Input((MAX_LEN, ), dtype=tf.int32)\n",
    "att = tf.keras.layers.Input((MAX_LEN, ), dtype=tf.int32)\n",
    "tok = tf.keras.layers.Input((MAX_LEN, ), dtype=tf.int32)\n",
    "\n",
    "from transformers import TFRobertaModel\n",
    "config = RobertaConfig.from_pretrained('config-roberta-base.json')\n",
    "bert_model = TFRobertaModel.from_pretrained('pretrained-roberta-base.h5',config=config)\n",
    "x = bert_model(ids,attention_mask=att,token_type_ids=tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3a160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2f752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae5aabb",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Tokenizer details from HF (refer to this if you want to train own tokenizer)\n",
    "    - https://huggingface.co/docs/tokenizers/pipeline\n",
    "    \n",
    "    \n",
    "2. difference between autotokenizer.from_pretrained and specifictokenizer.from_pretrained\n",
    "    - gs: huggingface autotokenizer different from tokenizer\n",
    "    - https://github.com/huggingface/transformers/issues/5587\n",
    "    \n",
    "\n",
    "3. Why do we use offsets?\n",
    "    - gs: huggingface tokenizer offsets\n",
    "    -\n",
    "https://huggingface.co/transformers/v4.2.2/custom_datasets.html#:~:text=For%20each%20sub%2Dtoken%20returned,its%20corresponding%20label%20to%20%2D100%20.\n",
    "\n",
    "\n",
    "4.Difference between token ids and attention mask\n",
    "- [ref](https://jaketae.github.io/category/common-sense/#:~:text=Input%20IDs%20are%20obvious%3A%20these,where%20two%20sentences%20are%20given.)\n",
    "\n",
    "- input IDs are obvious: these are simply mappings between tokens and their respective IDs. The attention mask is to prevent the model from looking at padding tokens. The token type IDs are used typically in a next sentence prediction tasks, where two sentences are given.\n",
    "\n",
    "\n",
    "5. Error from using TFRobertaModel\n",
    "- No module named 'keras.engine'\n",
    "- Due to most latest version of tensorflow ... \n",
    "- downloaded the tf_model.h5 and saved in current directory, but does work\n",
    "\n",
    "6. What doe conv1d(filters=1,kernel_size=1) mean\n",
    "- This means that we are using 1 filters (output channel), kernel_size=1 means specifies the length of the 1D convolution window.\n",
    "- Convolution is applied on the second dimension. eg (4, 10, 128) -> convolution is applied on dim=1 (i.e shape=(10,)). \n",
    "    - To run sample, need to use the convolution weights\n",
    "\n",
    "7. When to use crossentropy loss and when to use binary cross entropy loss\n",
    "- gs: (pytorch cross entropy loss vs binarycrossentropy loss)\n",
    "- https://medium.com/dejunhuang/learning-day-57-practical-5-loss-function-crossentropyloss-vs-bceloss-in-pytorch-softmax-vs-bd866c8a0d23\n",
    "    - BinaryCrossEntropy() loss should be used for binary, crossentropy loss should be used for multi-class classification\n",
    "    - Reason:\n",
    "       - crossentropy loss will take as input a target y that can take on values (0,C), and expects the predictions to be of shape (batch_size, num_classes)\n",
    "        - BinaryCrossEntropy loss will take in as input a target y that can take on values (0,1), and expects the predictions to be of shape (batch_size, 1)\n",
    "        - CrossEntropy can be used for binary classification. \n",
    "           - Using sigmoid\n",
    "               - Final output is shape (batch_size, 2) because crossentropy loss needs to take in predictions with (bsize, num_classes)\n",
    "               - This means that we use one sigmoid for each 0 and 1 prediction before feeding it into CrossEntropy loss. \n",
    "               - But output probabilities will be meaningless. eg σ([-2.34, 3.45])=[8.79%, 96.9%] does not make sense\n",
    "           - Using softmax\n",
    "               Final output is also of shape (batch_size, 2) because crossentropy loss requires predictions with shape (bsize,num_classes)\n",
    "           - However, for binary classification where there are only two classes, the output from softmax tends to always be close to 0 and close to one. Eg. softmax([-2,34, 3,45])=[0.3%, 99.7%]\n",
    "           - So softmax is only suitable for multi-class classification.\n",
    "           \n",
    "- When to use binarycrossentropy, crossentroppy loss\n",
    "    - TLDR: BCE: multilabel, binary classification, CE: multiclass\n",
    "- https://stackoverflow.com/questions/59336899/which-loss-function-and-metrics-to-use-for-multi-label-classification-with-very\n",
    "    - gs: multi label classification binarycross entorpy\n",
    "- https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451\n",
    "    - gs: crossentropy loss for multi label classification\n",
    "- https://discuss.pytorch.org/t/what-kind-of-loss-is-better-to-use-in-multilabel-classification/32203\n",
    "    - gs: loss function for multi label classification pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dfffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
